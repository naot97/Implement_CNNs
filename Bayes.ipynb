{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bayes.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"9VkEOsh9RHS7","colab_type":"text"},"cell_type":"markdown","source":["#Excercise of Bayes"]},{"metadata":{"id":"r0RNftt2rfS7","colab_type":"text"},"cell_type":"markdown","source":["\n","**Data gồm khoảng 2200 bài báo và có 5 category : business, entertainment, politics, sport và tech. Sau khi fit bằng bayes, check bằng data test thì độ chính xác khoảng 96% **\n","\n","Link Data thô : https://drive.google.com/drive/folders/1otI7Xhbk-Jzjg7fiNVSukbL1_c8R8FTw?usp=sharing\n","\n","Link Data đã xử lí thành table: https://drive.google.com/drive/folders/1EInZH9jzRhuPOfIRB44UANZWomk-P6uM?usp=sharing"]},{"metadata":{"id":"U-AUSiBRiHlf","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import re\n","import pickle\n","news_of_train = [469,355,375,460,360]\n","news_of_test = [41,31,42,51,41]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Nu3GHACwh5ox","colab_type":"text"},"cell_type":"markdown","source":["##Processes data to table and save"]},{"metadata":{"id":"0moA1Wpwh24-","colab_type":"code","colab":{}},"cell_type":"code","source":["def pre_data_1(num_data, dir_name):\n","\tC = len(num_data)\n","\tdata = []\n","\tlabel = []\n","\tfor i in range(C):\n","\t\tfor j in range(num_data[i]):\n","\t\t\tlink = dir_name + '\\\\' + str(i) + '\\\\' + str(j) +'.txt'\n","\t\t\tf = open(link, 'r', encoding='utf-8', errors='ignore')\n","\t\t\ts = f.read().lower()\n","\t\t\ts = re.sub(r'[\\d\\W\\t\\n\\r\\f\\v]', ' ', s )\n","\t\t\ts = re.sub(' +', ' ', s)\n","\t\t\tdata.append(s.split(' '))\n","\t\t\tlabel.append(i)\n","\treturn data, label\n","\n","def save_list(file_name, list):\n","\twith open(file_name,'wb') as f :\n","\t\tpickle.dump(list,f)\n","\n","def get_table(data, label, column):\n","\tx = []\n","\ty = []\n","\tfor i in range(len(data)):\n","\t\tt = []\n","\t\tfor j in range(len(column)):\n","\t\t\tif column[j] in data[i] :\n","\t\t\t\tt.append(1)\n","\t\t\telse : t.append(0)\n","\t\tx.append(t)\n","\t\ty.append(label[i])\n","\n","\treturn np.array(x), np.array(y)\n","\n","def pre_data():\n","\tglobal news_of_train,news_of_test,dir\n","\tdata_train,label_train = pre_data_1(news_of_train,'bbc\\\\train')\n","\tdata_test,label_test = pre_data_1(news_of_test,'bbc\\\\test')\n","\n","\tcolumn = list(set([item for sublist in data_train for item in sublist]))# list of word\n","\tcolumn = column[1:]# remove word \"\"\n","\n","\tx_train, y_train = get_table(data_train,label_train,column)\n","\tx_test,y_test = get_table(data_test,label_test,column)\t\n","\n","\tsave_list('list\\\\x_train.pkl',x_train)\n","\tsave_list('list\\\\y_train.pkl',y_train)\n","\tsave_list('list\\\\x_test.pkl',x_test)\n","\tsave_list('list\\\\y_test.pkl',y_test)\n","\tsave_list('list\\\\column.pkl',column)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wql_ShkeiYlG","colab_type":"text"},"cell_type":"markdown","source":["## Class Bayes"]},{"metadata":{"id":"9HgusOUwibfp","colab_type":"code","colab":{}},"cell_type":"code","source":["class Bayes:\n","\tdef fit(self,x, y):\n","\t\tself.C = len(set(y))\n","\t\tself.D = len(x[0])\n","\t\tself.theta = np.zeros((self.C,self.D))\n","\t\tself.prior = np.zeros(self.C)\n","\t\tfor c in range(self.C) :\n","\t\t\tx_in_c = x[y == c, :]\n","\t\t\tNon = np.sum(x_in_c, axis = 0 )\n","\t\t\tn_c = len(x_in_c)\n","\t\t\tself.prior[c] = n_c / len(x)\n","\t\t\tself.theta[c,:] = Non / n_c\n","\n","\tdef predict(self, x,y):\n","\t\tepxi = 0.00000000001\n","\t\tcount_correct = 0\n","\t\tnum_test = len(x)\n","\t\tfor i in range(num_test):\n","\t\t\tloglik = np.zeros(self.C) \n","\t\t\tfor c in range(self.C):\n","\t\t\t\ttheta = self.theta[c]\n","\t\t\t\tbitmask = x[i]\n","\t\t\t\tloglik[c] = np.log(self.prior[c] + epxi) +  np.sum( np.dot(bitmask, np.log(theta + epxi)) + np.dot(1-bitmask, np.log(1-theta + epxi)) )\n","\t\t\t\n","\t\t\ty_hat = np.argmax(loglik)\n","\t\t\tif (y_hat == y[i]) :\n","\t\t\t\tcount_correct += 1\n","\n","\t\treturn count_correct / num_test\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OD1cS2yBifdx","colab_type":"text"},"cell_type":"markdown","source":["## Main"]},{"metadata":{"id":"R1FBb3KVikL_","colab_type":"code","colab":{}},"cell_type":"code","source":["dic = load_data('list\\\\column.pkl')\n","x_train = load_data('list\\\\x_train.pkl')\n","y_train = load_data('list\\\\y_train.pkl')\n","x_test = load_data('list\\\\x_test.pkl')\n","y_test = load_data('list\\\\y_test.pkl')\n","b =  Bayes()\n","b.fit(x_train,y_train)\n","print('length of dictionary : %d words' %len(dic))\n","print('train data : %d rows' %len(y_train))\n","print('test data : %d rows' %len(y_test))\n","print('test accurary : %f'  % b.predict(x_test,y_test))\n"],"execution_count":0,"outputs":[]}]}